{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd3fefb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696a9533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/redditnews/RedditNews_FinBert.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_finbert \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/redditnews/RedditNews_FinBert.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_vader \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/redditnews/RedditNews_Vader.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_stock \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/redditnews/upload_DJIA_table_preprocessed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MasterThesis\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/redditnews/RedditNews_FinBert.csv'"
     ]
    }
   ],
   "source": [
    "df_finbert = pd.read_csv('/kaggle/input/redditnews/RedditNews_FinBert.csv')\n",
    "df_vader = pd.read_csv('/kaggle/input/redditnews/RedditNews_Vader.csv')\n",
    "\n",
    "df_stock = pd.read_csv('/kaggle/input/redditnews/upload_DJIA_table_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f48e922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T18:31:29.131245Z",
     "iopub.status.busy": "2023-07-24T18:31:29.130766Z",
     "iopub.status.idle": "2023-07-24T18:31:29.186280Z",
     "shell.execute_reply": "2023-07-24T18:31:29.185379Z",
     "shell.execute_reply.started": "2023-07-24T18:31:29.131214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the mean sentiment score for each stock for each day\n",
    "df_finbert = df_finbert.groupby('Date') \\\n",
    "       .agg({'sentiment_FinBert_positive':'mean',\n",
    "            'sentiment_FinBert_negative':'mean',\n",
    "            'sentiment_FinBert_neutral':'mean'}) \\\n",
    "       .rename(columns={'sentiment_FinBert_positive':'sentiment_FinBert_positive',\n",
    "                        'sentiment_FinBert_negative':'sentiment_FinBert_negative',\n",
    "                        'sentiment_FinBert_neutral':'sentiment_FinBert_neutral'}) \\\n",
    "       .reset_index()\n",
    "\n",
    "# Calculate the mean sentiment score for each stock for each day\n",
    "df_vader = df_vader.groupby('Date') \\\n",
    "       .agg({'sentiment_vader':'mean'}) \\\n",
    "       .rename(columns={'sentiment_vader':'sentiment_vader'}) \\\n",
    "       .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d04037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T18:31:30.091371Z",
     "iopub.status.busy": "2023-07-24T18:31:30.090488Z",
     "iopub.status.idle": "2023-07-24T18:31:30.118732Z",
     "shell.execute_reply": "2023-07-24T18:31:30.117827Z",
     "shell.execute_reply.started": "2023-07-24T18:31:30.091329Z"
    }
   },
   "outputs": [],
   "source": [
    "df_finbert = df_finbert.merge(df_stock[['Date', 'returns']], on='Date')\n",
    "df_vader = df_vader.merge(df_stock[['Date', 'returns']], on='Date')\n",
    "\n",
    "df_finbert['Date'] = pd.to_datetime(df_finbert['Date'])\n",
    "df_vader['Date'] = pd.to_datetime(df_vader['Date'])\n",
    "\n",
    "# set the index\n",
    "df_finbert.set_index('Date', inplace=True)\n",
    "df_vader.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e62e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T18:31:32.975447Z",
     "iopub.status.busy": "2023-07-24T18:31:32.975090Z",
     "iopub.status.idle": "2023-07-24T18:31:32.987114Z",
     "shell.execute_reply": "2023-07-24T18:31:32.986065Z",
     "shell.execute_reply.started": "2023-07-24T18:31:32.975418Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Define a function to prepare the data for the LSTM\n",
    "def prepare_data(data, timesteps):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(timesteps, len(data)):\n",
    "        X.append(data[i-timesteps:i])\n",
    "        y.append(data[i, -1])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def run_LSTM(df, timesteps = 60):\n",
    "    # Calculate the index to split the data\n",
    "    split_idx = int(len(df) * 0.8)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train = df.iloc[:split_idx]\n",
    "    test = df.iloc[split_idx:]\n",
    "    \n",
    "    # Prepare the training and testing data\n",
    "    X_train, y_train = prepare_data(train.values, timesteps)\n",
    "    X_test, y_test = prepare_data(test.values, timesteps)\n",
    "\n",
    "    # Get the number of features from the training data\n",
    "    num_features = X_train.shape[-1]\n",
    "\n",
    "    # Reshape the data to the format required by the LSTM\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], num_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], num_features))\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the LSTM layer\n",
    "    model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], num_features)))\n",
    "\n",
    "    # Add the output layer\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Define the callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10),\n",
    "        ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss'),\n",
    "        TensorBoard(log_dir='./logs')\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7d56ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T18:31:36.492127Z",
     "iopub.status.busy": "2023-07-24T18:31:36.491671Z",
     "iopub.status.idle": "2023-07-24T18:32:03.371515Z",
     "shell.execute_reply": "2023-07-24T18:32:03.370564Z",
     "shell.execute_reply.started": "2023-07-24T18:31:36.492087Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 8s 20ms/step - loss: 5.0446e-04 - val_loss: 7.1485e-05\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.7343e-04 - val_loss: 4.7185e-05\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6342e-04 - val_loss: 5.5559e-05\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.7195e-04 - val_loss: 5.1173e-05\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6305e-04 - val_loss: 5.6451e-05\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.7434e-04 - val_loss: 9.5213e-05\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.7132e-04 - val_loss: 5.6760e-05\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.7514e-04 - val_loss: 4.5116e-05\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 1.6496e-04 - val_loss: 4.4808e-05\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.5977e-04 - val_loss: 4.7753e-05\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6723e-04 - val_loss: 5.0955e-05\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.7030e-04 - val_loss: 7.5335e-05\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6777e-04 - val_loss: 7.9970e-05\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 2.2192e-04 - val_loss: 4.5202e-05\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6277e-04 - val_loss: 6.9898e-05\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.8528e-04 - val_loss: 8.5511e-05\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6987e-04 - val_loss: 4.5926e-05\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.7368e-04 - val_loss: 5.8547e-05\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6741e-04 - val_loss: 4.5135e-05\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 3s 19ms/step - loss: 1.9502e-04 - val_loss: 5.2698e-05\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6746e-04 - val_loss: 4.9640e-05\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6722e-04 - val_loss: 4.7964e-05\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6118e-04 - val_loss: 5.1083e-05\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6133e-04 - val_loss: 5.3845e-05\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6308e-04 - val_loss: 4.3026e-05\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6444e-04 - val_loss: 5.7146e-05\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6060e-04 - val_loss: 4.6363e-05\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.6010e-04 - val_loss: 4.4562e-05\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 1.5894e-04 - val_loss: 5.4171e-05\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6148e-04 - val_loss: 4.3608e-05\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6207e-04 - val_loss: 4.5859e-05\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6272e-04 - val_loss: 5.9351e-05\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.7217e-04 - val_loss: 5.0227e-05\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6400e-04 - val_loss: 6.8762e-05\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.6762e-04 - val_loss: 4.3312e-05\n",
      "11/11 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_finbert, y_test_finbert = run_LSTM(df_finbert)\n",
    "y_pred_vader, y_test_vader = run_LSTM(df_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5038db4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T18:41:28.881261Z",
     "iopub.status.busy": "2023-07-24T18:41:28.880832Z",
     "iopub.status.idle": "2023-07-24T18:41:28.889363Z",
     "shell.execute_reply": "2023-07-24T18:41:28.888193Z",
     "shell.execute_reply.started": "2023-07-24T18:41:28.881227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert them into pandas dataframes\n",
    "y_pred_finbert_df = pd.DataFrame(y_pred_finbert, columns=['y_pred_FinBert'])\n",
    "y_test_finbert_df = pd.DataFrame(y_test_finbert, columns=['y_test_FinBert'])\n",
    "y_pred_vader_df = pd.DataFrame(y_pred_vader, columns=['y_pred_Vader'])\n",
    "y_test_vader_df = pd.DataFrame(y_test_vader, columns=['y_test_Vader'])\n",
    "\n",
    "# Combine them into a single dataframe\n",
    "results = pd.concat([y_pred_finbert_df, y_test_finbert_df,y_pred_vader_df, y_test_vader_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dc844f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-24T18:42:48.623418Z",
     "iopub.status.busy": "2023-07-24T18:42:48.623043Z",
     "iopub.status.idle": "2023-07-24T18:42:48.636207Z",
     "shell.execute_reply": "2023-07-24T18:42:48.634952Z",
     "shell.execute_reply.started": "2023-07-24T18:42:48.623390Z"
    }
   },
   "outputs": [],
   "source": [
    "results\n",
    "results.to_csv('RedditNews_Results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
