{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-04T18:24:07.490002Z","iopub.execute_input":"2023-11-04T18:24:07.490381Z","iopub.status.idle":"2023-11-04T18:24:08.007727Z","shell.execute_reply.started":"2023-11-04T18:24:07.490340Z","shell.execute_reply":"2023-11-04T18:24:08.006297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = pd.read_csv('/kaggle/input/masterthesis-03-lstm/predictions.csv')\nresults = pd.read_csv('/kaggle/input/masterthesis-03-lstm/results.csv')\n# predictions = pd.read_csv('/kaggle/input/lsmt-predictions/predictions.csv')\n\n# Ensure 'Date' is in datetime format\npredictions['Date'] = pd.to_datetime(predictions['Date'])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:08.010049Z","iopub.execute_input":"2023-11-04T18:24:08.010690Z","iopub.status.idle":"2023-11-04T18:24:08.049665Z","shell.execute_reply.started":"2023-11-04T18:24:08.010645Z","shell.execute_reply":"2023-11-04T18:24:08.048748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:08.051665Z","iopub.execute_input":"2023-11-04T18:24:08.052558Z","iopub.status.idle":"2023-11-04T18:24:08.085706Z","shell.execute_reply.started":"2023-11-04T18:24:08.052509Z","shell.execute_reply":"2023-11-04T18:24:08.084244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adjust display settings\n\npd.set_option('display.max_colwidth', None)\npd.set_option('display.expand_frame_repr', False)\n\ndisplay(results[[\"Unnamed: 0\", \"RMSE\", \"MAPE\", \"R2 Score\", \"Best Parameters\"]])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:39:42.698706Z","iopub.execute_input":"2023-11-04T18:39:42.699247Z","iopub.status.idle":"2023-11-04T18:39:42.722599Z","shell.execute_reply.started":"2023-11-04T18:39:42.699197Z","shell.execute_reply":"2023-11-04T18:39:42.720562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scenarios = [\n#     'No_Sentiment', \n    'FinBERT_Sentiment', \n    'VADER_Sentiment']","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:09.430399Z","iopub.execute_input":"2023-11-04T18:24:09.430815Z","iopub.status.idle":"2023-11-04T18:24:09.440415Z","shell.execute_reply.started":"2023-11-04T18:24:09.430782Z","shell.execute_reply":"2023-11-04T18:24:09.438936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport pandas as pd\n\ndef plot_time_series(dates, y_true, y_pred, ax, title):\n    ax.plot(dates, y_true, label='Actual', marker='o')\n    ax.plot(dates, y_pred, label='Predicted', marker='x')\n    ax.set_title(title)\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Close Price')\n    ax.legend()\n    \n    # Formatting the date axis\n    ax.xaxis.set_major_locator(mdates.MonthLocator())  # major ticks every month\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))  # displaying major ticks as 'Month Year'\n    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)  # rotating major ticks\n\n\nfig, axes = plt.subplots(len(scenarios), 1, figsize=(12, 6 * len(scenarios)))\n\n\nfor i, scenario in enumerate(scenarios):\n    # Extract date, actual, and predicted values\n    dates = predictions['Date']\n    y_true = predictions['Close']\n    y_pred = predictions[f'{scenario}_predicted']\n    \n    # Time series plot of actual vs predicted\n    plot_time_series(dates, y_true, y_pred, axes[i], f\"Time Series of Actual vs Predicted: {scenario}\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:09.442959Z","iopub.execute_input":"2023-11-04T18:24:09.443385Z","iopub.status.idle":"2023-11-04T18:24:10.803732Z","shell.execute_reply.started":"2023-11-04T18:24:09.443348Z","shell.execute_reply":"2023-11-04T18:24:10.802572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_scatter(y_true, y_pred, ax, title):\n    ax.scatter(y_true, y_pred, alpha=0.5)\n    ax.set_title(title)\n    ax.set_xlabel('Actual')\n    ax.set_ylabel('Predicted')\n    # Plotting the line of equality\n    ax.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='red', linestyle='--')\n    \n# Assuming predictions_df contains 'Close' and the predicted values for each scenario\nfig, axes = plt.subplots(len(scenarios), 1, figsize=(8, 6 * len(scenarios)))\n\nfor i, scenario in enumerate(scenarios):\n    # Extract actual and predicted values\n    y_true = predictions['Close']\n    y_pred = predictions[f'{scenario}_predicted']\n    \n    # Scatter plot actual vs predicted\n    plot_scatter(y_true, y_pred, axes[i], f\"Scatter Plot of Actual vs Predicted: {scenario}\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:20.816695Z","iopub.execute_input":"2023-11-04T18:24:20.817074Z","iopub.status.idle":"2023-11-04T18:24:21.601311Z","shell.execute_reply.started":"2023-11-04T18:24:20.817043Z","shell.execute_reply":"2023-11-04T18:24:21.600005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport scipy.stats as stats\n\ndef analyze_residuals(y_true, y_pred, ax):\n    residuals = y_true - y_pred\n    \n    # QQ Plot\n    stats.probplot(residuals, dist=\"norm\", plot=ax[0])\n    ax[0].set_title(f\"QQ-plot of Errors: {scenario}\")\n    \n    # Histogram\n    ax[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n    ax[1].set_title(\"Histogram of Residuals\")\n    \n\nfig, axes = plt.subplots(len(scenarios), 2, figsize=(12, 6 * len(scenarios)))\n\nfor i, scenario in enumerate(scenarios):\n    \n    # Extract actual and predicted values\n    y_true = predictions['Close']\n    y_pred = predictions[f'{scenario}_predicted']\n    \n    # Run residual analysis\n    analyze_residuals(y_true, y_pred, axes[i])\n    axes[i, 0].set_ylabel(scenario)\n    \nplt.tight_layout()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:44:57.093277Z","iopub.execute_input":"2023-11-04T18:44:57.093784Z","iopub.status.idle":"2023-11-04T18:44:58.443828Z","shell.execute_reply.started":"2023-11-04T18:44:57.093743Z","shell.execute_reply":"2023-11-04T18:44:58.442551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom scipy import stats\n\n# Assuming your data is in a CSV file called 'data.csv'\ndata = predictions\n\n# Calculate the errors of predictions from each model\ndata['FinBERT_error'] = data['Close'] - data['FinBERT_Sentiment_predicted']\ndata['VADER_error'] = data['Close'] - data['VADER_Sentiment_predicted']\n\n# Calculate the difference in errors between the two models\ndata['error_diff'] = data['FinBERT_error'] - data['VADER_error']\n\ndef analyze_residuals(residuals):\n   \n    # QQ Plot\n    stats.probplot(residuals, dist=\"norm\", plot=axes[0])\n    axes[0].set_title(\"QQ-plot of Residuals Between the Models\")\n    axes[0].set_ylabel(\"Difference in Errors\")\n    \n    # Histogram\n    axes[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n    axes[1].set_title(\"Histogram of Residuals Between the Models\")\n    axes[1].set_xlabel(\"Difference in Errors\")\n    axes[1].set_ylabel(\"Frequency\")\n    \n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n# Run residual analysis\nanalyze_residuals(data['error_diff'])\n    \nplt.tight_layout()\nplt.show()\n\n# Conduct a Shapiro-Wilk test for normality\nshapiro_stat, shapiro_p_value = stats.shapiro(data['error_diff'])\n\n# Output the result of the Shapiro-Wilk test\nprint('Conducting a Shapiro-Wilk test for normality... ')\nprint(f'Shapiro-Wilk statistic: {shapiro_stat}')\nprint(f'Shapiro-Wilk p-value: {shapiro_p_value}')\nprint('')\n\n# If the p-value is greater than 0.05, the data is normal enough for a paired t-test\nif shapiro_p_value > 0.05:\n    print('The data is normally distributed')\n    # Conduct a paired t-test on the errors\n    t_stat, p_value = stats.ttest_rel(data['FinBERT_error'], data['VADER_error'])\n    \n    # Output the result of the t-test\n    print(f'T-statistic: {t_stat}')\n    print(f'P-value: {p_value}')\n    \n    # Interpret the result of the t-test\n    alpha = 0.05  # Set significance level\n    if p_value < alpha:\n        print('There is a statistically significant difference between the models.')\n    else:\n        print('There is not a statistically significant difference between the models.')\nelse:\n    print('The data is not normally distributed')\n        # Conduct a Wilcoxon Signed-Rank Test on the errors\n    wilcoxon_stat, wilcoxon_p_value = stats.wilcoxon(data['FinBERT_error'], data['VADER_error'])\n\n    # Output the result of the Wilcoxon Signed-Rank Test\n    print(f'Wilcoxon statistic: {wilcoxon_stat}')\n    print(f'Wilcoxon p-value: {wilcoxon_p_value}')\n\n    # Interpret the result of the Wilcoxon Signed-Rank Test\n    alpha = 0.05  # Set significance level\n    if wilcoxon_p_value < alpha:\n        print('There is a statistically significant difference between the models.')\n    else:\n        print('There is not a statistically significant difference between the models.')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T19:05:27.509834Z","iopub.execute_input":"2023-11-04T19:05:27.510319Z","iopub.status.idle":"2023-11-04T19:05:28.273392Z","shell.execute_reply.started":"2023-11-04T19:05:27.510281Z","shell.execute_reply":"2023-11-04T19:05:28.271941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport scipy.stats as stats\n\ndef plot_qq(residuals, ax, title):\n    \"\"\"\n    Plot QQ plot for residuals.\n    \n    Parameters:\n        residuals (pd.Series or np.array): Residuals (errors) from model predictions.\n        ax (matplotlib.axes): Matplotlib axes on which to plot.\n        title (str): Title for the plot.\n    \"\"\"\n    stats.probplot(residuals, dist=\"norm\", plot=ax)\n    ax.set_title(title)\n\n# Assuming predictions_df contains 'Date', 'Close', and the predicted values for each scenario\nfig, axes = plt.subplots(1, len(scenarios), figsize=(18, 6))\n\nfor i, scenario in enumerate(scenarios):\n    # Calculate residuals\n    y_true = predictions['Close']\n    y_pred = predictions[f'{scenario}_predicted']\n    residuals = y_true - y_pred\n    \n    # QQ-plot of residuals\n    plot_qq(data['error_diff'], axes[i], f\"QQ-plot of Errors: {scenario}\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:52:57.266511Z","iopub.execute_input":"2023-11-04T18:52:57.267137Z","iopub.status.idle":"2023-11-04T18:52:58.025706Z","shell.execute_reply.started":"2023-11-04T18:52:57.267090Z","shell.execute_reply":"2023-11-04T18:52:58.024128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.stats as stats\n\ndef perform_dagostino_test(residuals, scenario):\n    \"\"\"\n    Perform D'Agostino Test on residuals and print results.\n    \n    Parameters:\n        residuals (pd.Series or np.array): Residuals (errors) from model predictions.\n        scenario (str): Name of the scenario (for printing).\n    \"\"\"\n    k2, p_value = stats.normaltest(residuals)\n    print(f\"{scenario}: D’Agostino Test: k2 = {k2:.2f}, p_value = {p_value:.4f}\")\n\nfor scenario in scenarios:\n    # Calculate residuals\n    y_true = predictions['Close']\n    y_pred = predictions[f'{scenario}_predicted']\n    residuals = y_true - y_pred\n    \n    # Perform D’Agostino Test\n    perform_dagostino_test(residuals, scenario)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:22.508782Z","iopub.execute_input":"2023-11-04T18:24:22.509142Z","iopub.status.idle":"2023-11-04T18:24:22.527355Z","shell.execute_reply.started":"2023-11-04T18:24:22.509110Z","shell.execute_reply":"2023-11-04T18:24:22.526006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.stats as stats\n\ndef perform_kruskal_wallis_test(residuals_dict):\n    \"\"\"\n    Perform Kruskal-Wallis H Test on residuals and print results.\n    \n    Parameters:\n        residuals_dict (dict): Dictionary with scenario names as keys and residuals as values.\n    \"\"\"\n    # Extract residuals\n    residuals_list = [residuals for residuals in residuals_dict.values()]\n    \n    # Perform Kruskal-Wallis H Test\n    H_statistic, p_value = stats.kruskal(*residuals_list)\n    \n    print(f\"Kruskal-Wallis H Test: H_statistic = {H_statistic:.2f}, p_value = {p_value:.4f}\")\n\n\nresiduals_dict = {}\n\nfor scenario in scenarios:\n    # Calculate residuals\n    y_true = predictions['Close']\n    y_pred = predictions[f'{scenario}_predicted']\n    residuals = y_true - y_pred\n    \n    # Store residuals in dictionary\n    residuals_dict[scenario] = residuals\n    \n# Perform Kruskal-Wallis H Test\nperform_kruskal_wallis_test(residuals_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:22.796379Z","iopub.execute_input":"2023-11-04T18:24:22.797120Z","iopub.status.idle":"2023-11-04T18:24:22.811250Z","shell.execute_reply.started":"2023-11-04T18:24:22.797079Z","shell.execute_reply":"2023-11-04T18:24:22.809543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import combinations\n\ndef perform_pairwise_mann_whitney_u_test(residuals_dict):\n    \"\"\"\n    Perform pairwise Mann-Whitney U Tests on residuals and print results.\n    \n    Parameters:\n        residuals_dict (dict): Dictionary with scenario names as keys and residuals as values.\n    \"\"\"\n    # Get all combinations of scenarios\n    scenario_combinations = combinations(residuals_dict.keys(), 2)\n    \n    for scenario1, scenario2 in scenario_combinations:\n        # Perform Mann-Whitney U Test\n        U_statistic, p_value = stats.mannwhitneyu(residuals_dict[scenario1], residuals_dict[scenario2])\n        \n        print(f\"Mann-Whitney U Test between {scenario1} and {scenario2}: U_statistic = {U_statistic:.2f}, p_value = {p_value:.4f}\")\n\n# Assuming residuals_dict is previously defined\n# Perform pairwise Mann-Whitney U Tests\nperform_pairwise_mann_whitney_u_test(residuals_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T18:24:23.532543Z","iopub.execute_input":"2023-11-04T18:24:23.533179Z","iopub.status.idle":"2023-11-04T18:24:23.545026Z","shell.execute_reply.started":"2023-11-04T18:24:23.533144Z","shell.execute_reply":"2023-11-04T18:24:23.543451Z"},"trusted":true},"execution_count":null,"outputs":[]}]}